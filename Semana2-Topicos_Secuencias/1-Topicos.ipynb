{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado de tópicos\n",
    "\n",
    "El modelado de tópicos es una tarea de NLP que busca, dado un *corpus* de documentos,\n",
    "\n",
    "1. Descubrir los distintos *tópicos* latentes en el *corpus*, y\n",
    "2. Entender cada documento como una combinación de distintos tópicos.\n",
    "\n",
    "Antes de explicar qué es un tópico, veamos el modelo de datos. Tenemos lo siguiente:\n",
    "\n",
    "1. Un cuerpo $D$ de $N$ documentos $d_1, \\ldots, d_N$\n",
    "2. Cada documento $d_i$ es una colección de palabras, donde $d_{i,j} \\ge 0$ es el número de veces que la palabra $w_j$ aparece en el documento $d_i$ (representación **bag of words**)\n",
    "3. Al conjunto total de $W$ palabras $w_1, w_2, \\ldots, w_W$ de todo el cuerpo se le conoce como **diccionario**.\n",
    "\n",
    "### Ejemplo mínimo\n",
    "\n",
    "**Corpus**\n",
    "> $d_1$ = ``Como poco coco como, poco coco compro. Como compro poco coco, poco coco como``<br>\n",
    "> $d_2$ = ``A Cuesta le cuesta subir la cuesta, y en medio de la cuesta va y se acuesta``\n",
    "\n",
    "**Diccionario**\n",
    "> ``como, poco, coco, compro, a, cuesta, le, subir, la, y, en, medio, de, va, se, acuesta`` <br>\n",
    "> $W = 16$\n",
    "\n",
    "**Representación bag-of-words**\n",
    "> $d_1$ = ``{\"coco\": 4, \"como\": 4, \"compro\": 2, \"poco\": 4}`` <br>\n",
    "> $d_2$ = ``{\"a\": 1, \"acuesta\": 1, \"cuesta\": 4, \"de\": 1, \"en\": 1, \"la\": 2, \"le\": 1, \"medio\": 1, \"se\": 1, \"subir\": 1, \"va\": 1, \"y\": 2}``\n",
    "\n",
    "Entonces, un tópico $t$ es una combinación lineal de palabras del diccionario, de modo que $\\sum_{j=1}^{m} t_j = 1$.\n",
    "\n",
    "\n",
    "En términos matriciales, la entrada de nuestro método será una matriz $\\mathbf{D}$ de dimension $N \\times W$. Esta matriz muy seguramente será **dispersa**. Es decir, que la mayoría de sus valores serán 0. \n",
    "\n",
    "||como|poco|coco|compro|a|cuesta|le|subir|la|y|en|medio|de|va|se|acuesta|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "|$d_1$|4|4|4|2|0|0|0|0|0|0|0|0|0|0|0|0|\n",
    "|$d_2$|0|0|0|0|1|4|1|1|2|1|1|1|1|1|1|1|\n",
    "\n",
    "**Importante**: la información secuencial (cuál palabra sigue a cuál otra) se pierde en la representación *bag-of-words*. Luego estudiaremos otros modelos para esto. \n",
    "\n",
    "Finalmente, nuestro método de modelado de tópicos toma un valor $K$ (el número de tópicos a modelar) y va a producir lo siguiente:\n",
    "\n",
    "1. Una matriz de tópicos-palabras $T$ de dimensiones $K \\times W$\n",
    " - Es decir, de qué palabras se compone cada tópico (fila) $T_i$\n",
    " - De modo que $\\sum_{i=1}^W T_i = 1$\n",
    "\n",
    " \n",
    "2. Una matriz de documentos-tópicos $P$ de dimensiones $N \\times K$\n",
    " - Es decir, la fila $P_i$ nos explica de qué tópicos se compone el documento $d_i$\n",
    " - Igualmente, $\\sum_{i=1}^K P_i = 1$\n",
    "\n",
    "## Asignación Latente de Dirichlet (LDA)\n",
    "\n",
    "Uno de los mejores modelos de tópicos es la Asignación Latente de Dirichlet (LDA). \n",
    "\n",
    "Este modelo presenta una mejoría sobre métodos anteriores (como pLSA) en que es un modelo **bayesiano** que incorpora la siguiente suposición como información prior: **dentro de un *corpus*, la correspondencia entre documentos, palabras y tópicos será *dispersa***. \n",
    "\n",
    "Es decir, que un documento usualmente corresponde a **pocos tópicos**, y que los tópicos están compuestos de **pocas palabras**. Entonces, la gran mayoría de los elementos en las matrices $T$ y $P$ serán 0. \n",
    "\n",
    "### Dataset: 20 newsgroups\n",
    "\n",
    "Nuestro dataset de ejemplo será el conocido **20 newsgroups**. Este dataset contiene mensajes de 20 grupos de discusión de Usenet, divididos en varios tópicos, incluyendo política, religión, automovilismo, béisbol, computación, etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m             self.sock = self._context.wrap_socket(self.sock,\n\u001b[0m\u001b[1;32m   1425\u001b[0m                                                   server_hostname=server_hostname)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cc349a2216e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Obtenemos el dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_20newsgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremove\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'headers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'footers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quotes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Vemos el listado de grupos de discusión\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml-env/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml-env/lib/python3.8/site-packages/sklearn/datasets/_twenty_newsgroups.py\u001b[0m in \u001b[0;36mfetch_20newsgroups\u001b[0;34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing, return_X_y)\u001b[0m\n\u001b[1;32m    256\u001b[0m             logger.info(\"Downloading 20news dataset. \"\n\u001b[1;32m    257\u001b[0m                         \"This may take a few minutes.\")\n\u001b[0;32m--> 258\u001b[0;31m             cache = _download_20newsgroups(target_dir=twenty_home,\n\u001b[0m\u001b[1;32m    259\u001b[0m                                            cache_path=cache_path)\n\u001b[1;32m    260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml-env/lib/python3.8/site-packages/sklearn/datasets/_twenty_newsgroups.py\u001b[0m in \u001b[0;36m_download_20newsgroups\u001b[0;34m(target_dir, cache_path)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading dataset from %s (14 MB)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mARCHIVE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0marchive_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fetch_remote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mARCHIVE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Decompressing %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marchive_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml-env/lib/python3.8/site-packages/sklearn/datasets/_base.py\u001b[0m in \u001b[0;36m_fetch_remote\u001b[0;34m(remote, dirname)\u001b[0m\n\u001b[1;32m   1179\u001b[0m     file_path = (remote.filename if dirname is None\n\u001b[1;32m   1180\u001b[0m                  else join(dirname, remote.filename))\n\u001b[0;32m-> 1181\u001b[0;31m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m     \u001b[0mchecksum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sha256\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchecksum\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mchecksum\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0murl_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_splittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    543\u001b[0m                                   '_open', req)\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1393\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1352\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1123)>"
     ]
    }
   ],
   "source": [
    "# Obtenemos el dataset \n",
    "import sklearn.datasets\n",
    "tng = sklearn.datasets.fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Vemos el listado de grupos de discusión\n",
    "print('*** Grupos de discusión: \\n')\n",
    "print(*tng['target_names'], sep='\\n')\n",
    "\n",
    "# Vemos un mensaje de ejemplo\n",
    "print('\\n\\n*** Mensajes de ejemplo: \\n\\n', tng['data'][0], '\\n\\n---\\n\\n', tng['data'][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preparación de datos\n",
    "\n",
    "Uno de los aspectos más importantes a la hora de trabajar con un dataset para análisis de lenguaje natural es el preprocesamiento, el cual incluye la eliminación de información irrelevante como signos de puntuación, diferencias entre mayúsculas y minúsculas y **\"stop words\"**, es decir, palabras como conjunciones (\"to\", \"a\", \"it\"). La clase que utilizaremos para convertir los documentos en su representación *bag-of-words*, llamada ``sklearn.feature_extraction.text.CountVectorizer``, trae consigo la facilidad para eliminar stop words y símbolos de puntuación. Veamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tng' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-314a8988ccfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## Creamos una instancia de CountVectorizer usando stop words en inglés\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## y la \"entrenaremos\" con el primer documento para ver cómo resultan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mr\"(?u)\\b[a-zA-Z][a-zA-Z][a-zA-Z]+\\b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'*** ANTES: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtng\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tng' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Creamos una instancia de CountVectorizer usando stop words en inglés\n",
    "## y la \"entrenaremos\" con el primer documento para ver cómo resultan\n",
    "cv = CountVectorizer(stop_words='english', token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z][a-zA-Z]+\\b\").fit([tng['data'][0]])\n",
    "\n",
    "print('*** ANTES: ', tng['data'][0])\n",
    "print('*** DESPUES:\\n\\n',' '.join(cv.build_analyzer()(tng['data'][0])))\n",
    "tng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, procederemos a realizar esto mismo con el dataset entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Tokenizamos el dataset entero (toma unos diez segundos en ejecutarse)\n",
    "cv = CountVectorizer(stop_words='english', token_pattern=r\"(?u)\\b[a-zA-Z][a-zA-Z][a-zA-Z]+\\b\").fit(tng['data'])\n",
    "tng_matrix = cv.transform(tng['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutando LDA con ``scikit-learn``\n",
    "\n",
    "La clase de interés es ``sklearn.decomposition.LatentDirichletAllocation``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 10\n",
      "iteration: 2 of max_iter: 10\n",
      "iteration: 3 of max_iter: 10\n",
      "iteration: 4 of max_iter: 10\n",
      "iteration: 5 of max_iter: 10\n",
      "iteration: 6 of max_iter: 10\n",
      "iteration: 7 of max_iter: 10\n",
      "iteration: 8 of max_iter: 10\n",
      "iteration: 9 of max_iter: 10\n",
      "iteration: 10 of max_iter: 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "## Entrenamos el modelo LDA (toma un par de minutos)\n",
    "lda = LatentDirichletAllocation(n_components=20, verbose=True).fit(tng_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TOPICO  0\n",
      "['government' 'people' 'war' 'rights' 'state' 'states' 'turkish' 'right'\n",
      " 'public' 'united' 'national' 'law' 'security' 'american' 'privacy'\n",
      " 'armenian' 'information' 'new' 'world' 'muslims']\n",
      "\n",
      "\n",
      "*** TOPICO  1\n",
      "['gun' 'fbi' 'law' 'police' 'guns' 'people' 'koresh' 'don' 'crime'\n",
      " 'weapons' 'batf' 'government' 'think' 'firearms' 'control' 'use' 'like'\n",
      " 'just' 'did' 'illegal']\n",
      "\n",
      "\n",
      "*** TOPICO  2\n",
      "['game' 'team' 'games' 'year' 'play' 'season' 'hockey' 'players' 'win'\n",
      " 'league' 'player' 'good' 'baseball' 'don' 'period' 'pit' 'teams' 'think'\n",
      " 'hit' 'nhl']\n",
      "\n",
      "\n",
      "*** TOPICO  3\n",
      "['know' 'thanks' 'msg' 'food' 'mail' 'don' 'time' 'list' 'number' 'san'\n",
      " 'does' 'just' 'address' 'group' 'battery' 'looking' 'chinese' 'points'\n",
      " 'let' 'com']\n",
      "\n",
      "\n",
      "*** TOPICO  4\n",
      "['won' 'lost' 'mov' 'slave' 'use' 'period' 'health' 'drive' 'seattle'\n",
      " 'san' 'blue' 'number' 'master' 'new' 'rate' 'april' 'power' 'vancouver'\n",
      " 'red' 'national']\n",
      "\n",
      "\n",
      "*** TOPICO  5\n",
      "['people' 'don' 'just' 'think' 'like' 'say' 'know' 'does' 'way' 'point'\n",
      " 'good' 'time' 'make' 'really' 'did' 'right' 'want' 'believe' 'evidence'\n",
      " 'read']\n",
      "\n",
      "\n",
      "*** TOPICO  6\n",
      "['drug' 'drugs' 'ground' 'power' 'energy' 'current' 'voltage' 'science'\n",
      " 'research' 'like' 'japanese' 'circuit' 'university' 'carl' 'neutral'\n",
      " 'conductor' 'design' 'said' 'rockets' 'program']\n",
      "\n",
      "\n",
      "*** TOPICO  7\n",
      "['windows' 'dos' 'key' 'use' 'chip' 'using' 'encryption' 'know' 'clipper'\n",
      " 'like' 'keys' 'file' 'does' 'card' 'just' 'program' 'problem' 'message'\n",
      " 'time' 'don']\n",
      "\n",
      "\n",
      "*** TOPICO  8\n",
      "['like' 'car' 'just' 'drive' 'good' 'new' 'know' 'don' 'time' 'used'\n",
      " 'power' 'does' 'use' 'problem' 'bike' 'think' 'work' 'got' 'way' 'right']\n",
      "\n",
      "\n",
      "*** TOPICO  9\n",
      "['new' 'sale' 'theory' 'condition' 'shipping' 'art' 'cover' 'appears'\n",
      " 'man' 'book' 'universe' 'offer' 'wolverine' 'excellent' 'black' 'copies'\n",
      " 'larson' 'books' 'asking' 'price']\n",
      "\n",
      "\n",
      "*** TOPICO  10\n",
      "['window' 'use' 'server' 'motif' 'widget' 'edu' 'sun' 'set' 'file'\n",
      " 'available' 'application' 'mit' 'display' 'using' 'com' 'code' 'version'\n",
      " 'lib' 'xterm' 'subject']\n",
      "\n",
      "\n",
      "*** TOPICO  11\n",
      "['max' 'file' 'bhj' 'giz' 'entry' 'output' 'program' 'bxn' 'entries'\n",
      " 'printf' 'section' 'info' 'oname' 'build' 'rules' 'char' 'int' 'qax'\n",
      " 'okz' 'stream']\n",
      "\n",
      "\n",
      "*** TOPICO  12\n",
      "['edu' 'graphics' 'greek' 'pub' 'ray' 'mail' 'send' 'ftp' 'siggraph' 'com'\n",
      " 'list' 'file' 'site' 'objects' 'archive' 'greece' 'amiga' 'server'\n",
      " 'message' 'gov']\n",
      "\n",
      "\n",
      "*** TOPICO  13\n",
      "['armenian' 'armenians' 'turkey' 'university' 'azerbaijan' 'turkish'\n",
      " 'armenia' 'istanbul' 'professor' 'history' 'chz' 'ottoman' 'jews'\n",
      " 'population' 'new' 'genocide' 'russian' 'air' 'azeri' 'ankara']\n",
      "\n",
      "\n",
      "*** TOPICO  14\n",
      "['israel' 'israeli' 'arab' 'jews' 'jewish' 'edu' 'arabs' 'palestinian'\n",
      " 'palestinians' 'palestine' 'gaza' 'israelis' 'land' 'adam' 'objective'\n",
      " 'peace' 'lebanon' 'book' 'jerusalem' 'occupied']\n",
      "\n",
      "\n",
      "*** TOPICO  15\n",
      "['image' 'jpeg' 'images' 'file' 'gif' 'color' 'data' 'format' 'space'\n",
      " 'edu' 'files' 'bit' 'available' 'earth' 'use' 'version' 'nasa' 'software'\n",
      " 'display' 'ftp']\n",
      "\n",
      "\n",
      "*** TOPICO  16\n",
      "['god' 'jesus' 'people' 'bible' 'christian' 'church' 'christ' 'believe'\n",
      " 'does' 'christians' 'faith' 'say' 'know' 'lord' 'life' 'did' 'said' 'man'\n",
      " 'think' 'love']\n",
      "\n",
      "\n",
      "*** TOPICO  17\n",
      "['edu' 'said' 'com' 'know' 'didn' 'went' 'people' 'don' 'time' 'just'\n",
      " 'came' 'home' 'like' 'told' 'started' 'going' 'says' 'saw' 'say'\n",
      " 'children']\n",
      "\n",
      "\n",
      "*** TOPICO  18\n",
      "['think' 'space' 'don' 'people' 'president' 'going' 'know' 'time' 'like'\n",
      " 'just' 'make' 'money' 'said' 'new' 'year' 'did' 'years' 'stephanopoulos'\n",
      " 'work' 'government']\n",
      "\n",
      "\n",
      "*** TOPICO  19\n",
      "['software' 'use' 'edu' 'mac' 'data' 'computer' 'mail' 'scsi' 'like'\n",
      " 'thanks' 'available' 'need' 'does' 'email' 'know' 'new' 'card'\n",
      " 'information' 'bit' 'drive']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Y, ahora, vamos a ver cómo se ven los tópicos. \n",
    "import numpy as np\n",
    "comp = lda.components_\n",
    "vec = np.array(cv.get_feature_names())\n",
    "for i in range(0, comp.shape[0]):\n",
    "    print('*** TOPICO ', i)\n",
    "    print(vec[comp[i].argsort()[-20:][::-1]])\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sale:\n",
      "\n",
      "Fujitsu 324meg SCSI drive.  $450\n",
      "\n",
      "Maxtor 338meg ESDI drive.  $425\n",
      "\n",
      "Maxtor 160meg ESDI drive.  $225\n",
      "\n",
      "Toshiba 106meg IDE drive.  $175\n",
      "\n",
      "XT case & motherboard.  $50\n",
      "\n",
      "DTC 16-bit MFM 2HD 2FD controler.  $30\n",
      "\n",
      "All items are used, in full working condition, and have a  \n",
      "warranty for one week unless otherwise specified.  All prices \n",
      "are %100 negotiable, shipping not included. \n",
      "\n",
      "Wanted:  \n",
      "\n",
      "Developers kit for SB\n",
      "17\" SVGA moniters (two of them).\n",
      "\n",
      "\n",
      "TOPICOS (en orden):\n",
      "[19  8  4  9  7 10 18 15  1 17  5  6 16  0  3  2 11 12 14 13]\n"
     ]
    }
   ],
   "source": [
    "## Ahora, veamos la composición de tópicos de algún documento\n",
    "\n",
    "print(tng['data'][1234])\n",
    "tx = lda.transform(tng_matrix[1234])\n",
    "\n",
    "print('TOPICOS (en orden):')\n",
    "print(tx.argsort()[0][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
